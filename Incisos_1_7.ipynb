{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparacion de las librerias a utilizar en el laboratorio"
      ],
      "metadata": {
        "id": "j9WFnV0S_hlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NOmE8Bql_RXT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos el data set desde la libreria de Keras"
      ],
      "metadata": {
        "id": "L4Ao34lx_pUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos MNIST\n",
        "(X_entreno, y_entreno), (X_prueba, y_prueba) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalizar los datos\n",
        "X_entreno = X_entreno / 255.0\n",
        "X_prueba = X_prueba / 255.0\n",
        "\n",
        "# Aplanar las imágenes\n",
        "X_entreno = X_entreno.reshape(-1, 28*28)\n",
        "X_prueba = X_prueba.reshape(-1, 28*28)\n",
        "\n",
        "# Crear el modelo\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "test_loss, test_acc = model.evaluate(X_prueba, y_prueba)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbAcYcNgARmO",
        "outputId": "dd3b84a9-49b7-40a3-fd1e-f1e696dff43f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.4716 - val_accuracy: 0.9569 - val_loss: 0.1493\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1323 - val_accuracy: 0.9663 - val_loss: 0.1175\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0863 - val_accuracy: 0.9690 - val_loss: 0.1013\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0629 - val_accuracy: 0.9741 - val_loss: 0.0928\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0456 - val_accuracy: 0.9747 - val_loss: 0.0860\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0371 - val_accuracy: 0.9735 - val_loss: 0.0890\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0288 - val_accuracy: 0.9709 - val_loss: 0.1043\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0218 - val_accuracy: 0.9758 - val_loss: 0.0896\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0186 - val_accuracy: 0.9761 - val_loss: 0.0898\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 0.9747 - val_loss: 0.1002\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1097\n",
            "Test accuracy: 0.9733999967575073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 1 - Modificar el tamaño de la capa oculta del modelo."
      ],
      "metadata": {
        "id": "KeIO3bZEAUZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Lista de tamaños de capa oculta a probar\n",
        "hidden_layer_sizes = [50, 100, 200, 300, 500]\n",
        "\n",
        "# Tabla para documentar resultados\n",
        "results = []\n",
        "\n",
        "for size in hidden_layer_sizes:\n",
        "    # Crear el modelo con el tamaño de capa oculta actual\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(size, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Medir el tiempo de entrenamiento\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "    val_acc = history.history['val_accuracy'][-1]\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    # Guardar los resultados\n",
        "    results.append((size, val_acc, training_time))\n",
        "\n",
        "# Imprimir los resultados\n",
        "for size, val_acc, training_time in results:\n",
        "    print(f'Tamaño de capa oculta: {size}, Precisión de validación: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G71O-GLAT4V",
        "outputId": "7bb1741e-e099-4da0-a08e-5bd08bb6d75d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de capa oculta: 50, Precisión de validación: 0.9692500233650208, Tiempo de entrenamiento: 40.55 segundos\n",
            "Tamaño de capa oculta: 100, Precisión de validación: 0.9742500185966492, Tiempo de entrenamiento: 50.66 segundos\n",
            "Tamaño de capa oculta: 200, Precisión de validación: 0.9764999747276306, Tiempo de entrenamiento: 74.61 segundos\n",
            "Tamaño de capa oculta: 300, Precisión de validación: 0.9770833253860474, Tiempo de entrenamiento: 89.31 segundos\n",
            "Tamaño de capa oculta: 500, Precisión de validación: 0.9775833487510681, Tiempo de entrenamiento: 94.64 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Cómo cambia la precisión de validación del modelo?\n",
        "  - Entre las iteraciones de capas que utilice la precisión no aumenta significativamente, pero si queremos un modelo perfecto el gap de entre 200 y 300 de capa oculta puede ser muy beneficioso porque la variación de presición no es mucha pero si que es una precisión muy buena.\n",
        "- ¿Cuánto tiempo tarda el algoritmo en entrenar?\n",
        "  - Resultados de tiempo arriba\n"
      ],
      "metadata": {
        "id": "WGYmSQtLiM1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 2  - Modificación de la Profundidad de la Red"
      ],
      "metadata": {
        "id": "7e5w5njIWvkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo con una capa oculta adicional\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),  # Capa oculta adicional\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time = time.time()\n",
        "history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, verbose=0)\n",
        "end_time = time.time()\n",
        "\n",
        "# Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f'Precisión de validación con capa adicional: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "datOtJnYW1Zv",
        "outputId": "b5cfe2fb-be86-4ef4-df07-b60a413d1169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión de validación con capa adicional: 0.9747499823570251, Tiempo de entrenamiento: 62.39 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compare la precisión de validación con el modelo original\n",
        "  - El aumento de presición no es demasiado ya que el original ya tenía una presición muy cercana, pero en cuanto a precisión neta si que mejora al modelo original.\n",
        "- Analice el impacto en el tiempo de ejecución\n",
        "  - Me quedaría con el modelo original, precisión ligeramente menor pero un tiempo más corto, obviamente en cuanto escalemos los modelos y la dimensión sea más grande me quedaría con este de profundidad mayor ya que el gap si que llegaría a aumentar demasiado.\n",
        "- Explique los cambios necesarios en el código para implementar esta modificación\n",
        "  - Se agrego una capa más como se muestra arriba y es de tipo relu también."
      ],
      "metadata": {
        "id": "f1Chbf0Ti_Nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 3 - Redes Profundas"
      ],
      "metadata": {
        "id": "1OjW7AUvW43s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de profundidades a probar\n",
        "depths = [2, 3, 4, 5]\n",
        "\n",
        "# Tabla para documentar resultados\n",
        "results_depth = []\n",
        "\n",
        "for depth in depths:\n",
        "    # Crear el modelo con la profundidad actual\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,))\n",
        "    ])\n",
        "\n",
        "    for _ in range(depth - 1):\n",
        "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Medir el tiempo de entrenamiento\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "    val_acc = history.history['val_accuracy'][-1]\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    # Guardar los resultados\n",
        "    results_depth.append((depth, val_acc, training_time))\n",
        "\n",
        "# Imprimir los resultados\n",
        "for depth, val_acc, training_time in results_depth:\n",
        "    print(f'Profundidad: {depth}, Precisión de validación: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzjfC7zoW86w",
        "outputId": "bb257ef3-891e-4e83-c179-c1306218da23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profundidad: 2, Precisión de validación: 0.9737499952316284, Tiempo de entrenamiento: 61.79 segundos\n",
            "Profundidad: 3, Precisión de validación: 0.9780833125114441, Tiempo de entrenamiento: 78.94 segundos\n",
            "Profundidad: 4, Precisión de validación: 0.9739166498184204, Tiempo de entrenamiento: 67.85 segundos\n",
            "Profundidad: 5, Precisión de validación: 0.9765833616256714, Tiempo de entrenamiento: 78.26 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Analice la relación entre profundidad y tiempo de ejecución\n",
        " - Creo que es bastante evidente la relación que entre más profundidad el tiempo también aumenta aunque en este caso hubo una anomalia en la de profundidad 4 tardando menos que la de profundidad 3.\n",
        "- Identifique posibles problemas de desvanecimiento del gradiente\n",
        "  Puede ser que al llegar a cierta \"anchura\" el modelo llegue a perder mejora y el desvanecimiento del gradiente ya no llegue a cambiar."
      ],
      "metadata": {
        "id": "LkULir8aj5O4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 4 - Funciones de Activación I"
      ],
      "metadata": {
        "id": "MstIylftXAR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo con activación sigmoidal\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time = time.time()\n",
        "history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, verbose=0)\n",
        "end_time = time.time()\n",
        "\n",
        "# Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f'Precisión de validación con activación sigmoidal: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zMWmXdXXGaU",
        "outputId": "f75c8398-2baf-428d-d24d-26bacf364aa8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión de validación con activación sigmoidal: 0.9738333225250244, Tiempo de entrenamiento: 74.03 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 5 - Funciones de Activación II"
      ],
      "metadata": {
        "id": "DjXf2Of0XG-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo con ReLU en la primera capa y tanh en la segunda\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(128, activation='tanh'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time = time.time()\n",
        "history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, verbose=0)\n",
        "end_time = time.time()\n",
        "\n",
        "# Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f'Precisión de validación con ReLU y tanh: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6aNsiwZXNPW",
        "outputId": "d5ad4b87-053b-438f-a728-5396c2a2bd83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión de validación con ReLU y tanh: 0.9775000214576721, Tiempo de entrenamiento: 73.07 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 6 - Tamaño de Batch Grande"
      ],
      "metadata": {
        "id": "jE6mghRpXQB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo base\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Medir el tiempo de entrenamiento con batch size grande\n",
        "start_time = time.time()\n",
        "history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, batch_size=10000, verbose=0)\n",
        "end_time = time.time()\n",
        "\n",
        "# Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f'Precisión de validación con batch size 10,000: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXcZWYkoXSXk",
        "outputId": "4fd4edec-c9d7-4b9c-f17b-05f718e53f87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión de validación con batch size 10,000: 0.9099166393280029, Tiempo de entrenamiento: 8.55 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inciso 7 - Descenso de Gradiente Estocástico (SGD)"
      ],
      "metadata": {
        "id": "Ubf-cp2IXWUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo base\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Medir el tiempo de entrenamiento con SGD puro\n",
        "start_time = time.time()\n",
        "history = model.fit(X_entreno, y_entreno, epochs=10, validation_split=0.2, batch_size=1, verbose=0)\n",
        "end_time = time.time()\n",
        "\n",
        "# Obtener la precisión de validación y el tiempo de entrenamiento\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f'Precisión de validación con SGD puro: {val_acc}, Tiempo de entrenamiento: {training_time:.2f} segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4P8Cq4bXeBM",
        "outputId": "580e0b5b-b577-48b2-8ffd-f33b319cfa37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión de validación con SGD puro: 0.9707499742507935, Tiempo de entrenamiento: 1361.04 segundos\n"
          ]
        }
      ]
    }
  ]
}